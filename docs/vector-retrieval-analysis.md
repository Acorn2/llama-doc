# å‘é‡æ£€ç´¢ä½¿ç”¨åˆ†æ

## ğŸ¯ æ ¸å¿ƒç»“è®º

**æ˜¯çš„ï¼Œä¸¤ç§å¯¹è¯æ¨¡å¼éƒ½ä¼šä½¿ç”¨çŸ¥è¯†åº“çš„æ–‡ä»¶å‘é‡è¿›è¡Œæ£€ç´¢ï¼Œä½†ä½¿ç”¨æ–¹å¼å’Œæ·±åº¦æœ‰æ‰€ä¸åŒã€‚**

ä¸¤ç§æ¨¡å¼éƒ½éµå¾ªç›¸åŒçš„åŸºæœ¬æµç¨‹ï¼š
1. **æ¥æ”¶ç”¨æˆ·é—®é¢˜**
2. **æ ¹æ®é—®é¢˜æœç´¢ç›¸å…³å‘é‡** 
3. **åŸºäºæ£€ç´¢ç»“æœè¿›è¡Œåç»­æ“ä½œ**

ä½†åœ¨å…·ä½“å®ç°å’Œä½¿ç”¨æ·±åº¦ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚

## ğŸ” å‘é‡æ£€ç´¢çš„å…±åŒåŸºç¡€æ¶æ„

### æ ¸å¿ƒç»„ä»¶
- **å‘é‡æ•°æ®åº“**: Qdrant 1.7.1
- **åµŒå…¥æ¨¡å‹**: ModelFactory.create_embeddings()
- **å‘é‡å­˜å‚¨ç®¡ç†**: QdrantAdapter
- **æ£€ç´¢æ¥å£**: LangChainAdapter.create_langchain_retriever()

### ç»Ÿä¸€çš„æ£€ç´¢æµç¨‹
```python
# 1. ç”ŸæˆæŸ¥è¯¢å‘é‡
query_embedding = embeddings.embed_query(user_question)

# 2. åœ¨Qdrantä¸­æœç´¢ç›¸ä¼¼å‘é‡
search_results = qdrant_client.search(
    collection_name=f"kb_{kb_id}",
    query_vector=query_embedding,
    limit=top_k,
    with_payload=True
)

# 3. æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
formatted_results = format_search_results(search_results)
```

## ğŸ¤– Agentæ¨¡å¼çš„å‘é‡æ£€ç´¢ä½¿ç”¨

### æ£€ç´¢è·¯å¾„
```
ç”¨æˆ·è¯·æ±‚ â†’ AgentService â†’ LangChainDocumentAgent â†’ Agentå·¥å…·é“¾ â†’ å‘é‡æ£€ç´¢
```

### è¯¦ç»†æµç¨‹åˆ†æ

#### 1. å·¥å…·çº§åˆ«çš„å‘é‡æ£€ç´¢
Agentæ¨¡å¼é€šè¿‡ä¸‰ä¸ªä¸“ä¸šå·¥å…·ä½¿ç”¨å‘é‡æ£€ç´¢ï¼š

```python
# DocumentAnalysisTool - æ·±åº¦æ–‡æ¡£åˆ†æ
class DocumentAnalysisTool(BaseTool):
    def _run(self, query: str) -> str:
        retriever = self.adapter.create_langchain_retriever(self.kb_id)
        docs = retriever.get_relevant_documents(query)
        # è¿›è¡Œæ·±åº¦åˆ†æå¤„ç†
        return analyzed_content

# KnowledgeSearchTool - æ™ºèƒ½çŸ¥è¯†æœç´¢  
class KnowledgeSearchTool(BaseTool):
    def _run(self, query: str) -> str:
        retriever = self.adapter.create_langchain_retriever(self.kb_id)
        docs = retriever.get_relevant_documents(query)
        # æ ¼å¼åŒ–æœç´¢ç»“æœ
        return formatted_results

# SummaryTool - æ‘˜è¦ç”Ÿæˆ
class SummaryTool(BaseTool):
    def _run(self, query: str = "ç”Ÿæˆæ–‡æ¡£æ‘˜è¦") -> str:
        retriever = self.adapter.create_langchain_retriever(self.kb_id)
        docs = retriever.get_relevant_documents("æ–‡æ¡£ä¸»è¦å†…å®¹ æ ¸å¿ƒè§‚ç‚¹")
        # ç”Ÿæˆæ™ºèƒ½æ‘˜è¦
        return summary
```

#### 2. é«˜çº§æ£€ç´¢ç‰¹æ€§
```python
class SafeRetriever:
    def get_relevant_documents(self, query: str) -> List[Document]:
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.embeddings.embed_query(query)
        
        # æ‰§è¡Œå‘é‡æœç´¢
        search_results = self.qdrant_client.search(
            collection_name=self.collection_name,
            query_vector=query_embedding,
            limit=5,
            with_payload=True
        )
        
        # é«˜çº§è¿‡æ»¤å’Œè´¨é‡è¯„ä¼°
        documents = []
        for result in search_results:
            payload = result.get('payload', {})
            content = payload.get('content', '')
            
            # å†…å®¹è´¨é‡æ£€æŸ¥
            if content and content.strip():
                doc = Document(
                    page_content=content.strip(),
                    metadata={
                        'similarity_score': result.get('score', 0.0),
                        'quality_score': payload.get('quality_score', 0.5),
                        'keywords': payload.get('keywords', []),
                        # æ›´å¤šå…ƒæ•°æ®...
                    }
                )
                documents.append(doc)
        
        return documents
```

### Agentæ¨¡å¼æ£€ç´¢ç‰¹ç‚¹
- âœ… **å¤šå·¥å…·åä½œæ£€ç´¢**: ä¸åŒå·¥å…·é’ˆå¯¹ä¸åŒä»»åŠ¡ä¼˜åŒ–æ£€ç´¢ç­–ç•¥
- âœ… **æ™ºèƒ½ç»“æœå¤„ç†**: æ·±åº¦åˆ†ææ£€ç´¢ç»“æœï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯
- âœ… **ä¸Šä¸‹æ–‡ç†è§£**: èƒ½å¤Ÿç†è§£å¤æ‚æŸ¥è¯¢æ„å›¾ï¼Œè¿›è¡Œå¤šè½®æ£€ç´¢
- âœ… **è´¨é‡è¯„ä¼°**: å¯¹æ£€ç´¢ç»“æœè¿›è¡Œè´¨é‡è¯„åˆ†å’Œè¿‡æ»¤
- âœ… **ç¼“å­˜ä¼˜åŒ–**: Agentå®ä¾‹ç¼“å­˜ï¼Œæ£€ç´¢å™¨å¤ç”¨

## ğŸ’¬ Conversationæ¨¡å¼çš„å‘é‡æ£€ç´¢ä½¿ç”¨

### æ£€ç´¢è·¯å¾„
```
ç”¨æˆ·è¯·æ±‚ â†’ ConversationManager â†’ KnowledgeBaseManager â†’ å‘é‡æ£€ç´¢
```

### è¯¦ç»†æµç¨‹åˆ†æ

#### 1. ç›´æ¥å‘é‡æ£€ç´¢è°ƒç”¨
```python
def generate_response(self, db, conversation_id, user_message, ...):
    # è·å–çŸ¥è¯†åº“ID
    kb_id = conversation.kb_id
    
    # ç›´æ¥è°ƒç”¨çŸ¥è¯†åº“æœç´¢
    search_results = self.kb_manager.search_knowledge_base(
        kb_id=kb_id,
        query=user_message,  # ç›´æ¥ä½¿ç”¨ç”¨æˆ·æ¶ˆæ¯ä½œä¸ºæŸ¥è¯¢
        top_k=5,
        db=db
    )
    
    # æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡
    context = self.get_conversation_context(db, conversation_id)
    
    # ä½¿ç”¨LangChainé€‚é…å™¨ç”Ÿæˆå›å¤
    if langchain_adapter:
        response = langchain_adapter.generate_conversation_response(
            kb_id=kb_id,
            user_message=user_message,
            context=context,
            search_results=search_results,
            stream=stream
        )
```

#### 2. çŸ¥è¯†åº“å±‚é¢çš„å‘é‡æœç´¢
```python
def search_knowledge_base(self, kb_id, query, top_k=5, db=None):
    # è·å–å‘é‡å­˜å‚¨åç§°
    vector_store_name = f"kb_{kb_id}"
    
    # ç”ŸæˆæŸ¥è¯¢å‘é‡
    query_embedding = self.vector_store_manager.embeddings.embed_query(query)
    
    # æ‰§è¡Œå‘é‡æœç´¢
    search_results = self.vector_store_manager.qdrant_client.search(
        collection_name=vector_store_name,
        query_vector=query_embedding,
        limit=top_k,
        with_payload=True
    )
    
    # åŸºç¡€æ ¼å¼åŒ–
    formatted_results = []
    for result in search_results:
        payload = result.get('payload', {})
        formatted_results.append({
            "content": payload.get("content", ""),
            "chunk_id": payload.get("chunk_id", ""),
            "similarity_score": result.get('score', 0.0),
            "metadata": {
                "keywords": payload.get("keywords", []),
                "summary": payload.get("summary", "")
            }
        })
    
    return formatted_results
```

### Conversationæ¨¡å¼æ£€ç´¢ç‰¹ç‚¹
- âœ… **ç®€å•ç›´æ¥æ£€ç´¢**: ç”¨æˆ·é—®é¢˜ç›´æ¥ä½œä¸ºæ£€ç´¢æŸ¥è¯¢
- âœ… **å¿«é€Ÿå“åº”**: æœ€å°åŒ–çš„æ£€ç´¢å¤„ç†ï¼Œä¼˜åŒ–å“åº”é€Ÿåº¦
- âœ… **ä¸Šä¸‹æ–‡æ•´åˆ**: ç»“åˆå¯¹è¯å†å²å’Œæ£€ç´¢ç»“æœ
- âœ… **æ•°æ®åº“é›†æˆ**: ä¸å¯¹è¯æŒä¹…åŒ–ç´§å¯†ç»“åˆ
- âš ï¸ **åŸºç¡€å¤„ç†**: ç›¸å¯¹ç®€å•çš„ç»“æœå¤„ç†å’Œæ ¼å¼åŒ–

## ğŸ“Š ä¸¤ç§æ¨¡å¼çš„å‘é‡æ£€ç´¢å¯¹æ¯”

| ç»´åº¦ | Agentæ¨¡å¼ | Conversationæ¨¡å¼ |
|------|-----------|------------------|
| **æ£€ç´¢æ·±åº¦** | ğŸ”¥ å¤šå±‚æ¬¡ã€å¤šå·¥å…·æ£€ç´¢ | ğŸ“ å•å±‚ç›´æ¥æ£€ç´¢ |
| **æŸ¥è¯¢ä¼˜åŒ–** | ğŸ§  æ™ºèƒ½æŸ¥è¯¢é‡å†™å’Œæ‰©å±• | ğŸ’¬ åŸå§‹ç”¨æˆ·æŸ¥è¯¢ |
| **ç»“æœå¤„ç†** | ğŸ› ï¸ æ·±åº¦åˆ†æå’Œç»“æ„åŒ– | ğŸ“‹ åŸºç¡€æ ¼å¼åŒ– |
| **ç¼“å­˜ç­–ç•¥** | ğŸ—„ï¸ æ£€ç´¢å™¨å®ä¾‹ç¼“å­˜ | ğŸ’¨ å³æ—¶æ£€ç´¢ |
| **è´¨é‡æ§åˆ¶** | âœ… å¤šç»´åº¦è´¨é‡è¯„ä¼° | âš–ï¸ åŸºç¡€ç›¸ä¼¼åº¦æ’åº |
| **å“åº”æ—¶é—´** | â° è¾ƒæ…¢ï¼ˆæ·±åº¦å¤„ç†ï¼‰ | âš¡ å¿«é€Ÿ |
| **æ£€ç´¢ç²¾åº¦** | ğŸ¯ é«˜ç²¾åº¦ï¼ˆå¤šè½®ä¼˜åŒ–ï¼‰ | ğŸ“ ä¸­ç­‰ç²¾åº¦ |

## ğŸ”§ æŠ€æœ¯å®ç°ç»†èŠ‚å¯¹æ¯”

### Agentæ¨¡å¼çš„LCELé“¾æ„å»º
```python
def create_conversation_chain(self, kb_id: str):
    retriever = self.create_langchain_retriever(kb_id)
    
    prompt = ChatPromptTemplate.from_template("""
    åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ï¼š
    æ–‡æ¡£å†…å®¹ï¼š{context}
    ç”¨æˆ·é—®é¢˜ï¼š{question}
    è¯·åŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹ç»™å‡ºå‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚
    """)
    
    def format_docs(docs):
        # é«˜çº§æ–‡æ¡£æ ¼å¼åŒ–å’Œè¿‡æ»¤
        valid_contents = []
        for doc in docs:
            if doc.page_content and doc.page_content.strip():
                valid_contents.append(doc.page_content.strip())
        return "\n\n".join(valid_contents) if valid_contents else "æš‚æ— ç›¸å…³æ–‡æ¡£å†…å®¹"
    
    # LCELé“¾ï¼šæ£€ç´¢å™¨ â†’ æ ¼å¼åŒ– â†’ æç¤º â†’ LLM â†’ è§£æ
    chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | self.llm
        | StrOutputParser()
    )
    
    return chain
```

### Conversationæ¨¡å¼çš„ç®€å•æ£€ç´¢
```python
def _generate_simple_response(self, user_message, context, search_results):
    # æ„å»ºç®€å•æç¤º
    context_text = "\n\n".join([
        f"{msg['role']}: {msg['content']}"
        for msg in context[-5:]  # ä»…ä½¿ç”¨æœ€è¿‘5æ¡æ¶ˆæ¯
    ])
    
    search_text = "\n\n".join([
        f"æ–‡æ¡£ç‰‡æ®µ {i+1}:\n{result['content']}"
        for i, result in enumerate(search_results[:3])  # ä»…ä½¿ç”¨å‰3æ¡ç»“æœ
    ])
    
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼ŒåŸºäºä»¥ä¸‹å¯¹è¯å†å²å’ŒçŸ¥è¯†åº“æ£€ç´¢ç»“æœå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
    å¯¹è¯å†å²: {context_text}
    çŸ¥è¯†åº“æ£€ç´¢ç»“æœ: {search_text}
    è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜: {user_message}
    """
    
    # ç›´æ¥è°ƒç”¨LLM
    response = self.llm.predict(prompt)
    return response.strip()
```

## ğŸ¯ ä½¿ç”¨åœºæ™¯å»ºè®®

### é€‰æ‹©Agentæ¨¡å¼å½“éœ€è¦ï¼š
- ğŸ” **ç²¾ç¡®æ£€ç´¢**: éœ€è¦é«˜ç²¾åº¦çš„æ–‡æ¡£æ£€ç´¢å’Œåˆ†æ
- ğŸ§  **æ·±åº¦ç†è§£**: å¤æ‚æŸ¥è¯¢æ„å›¾ç†è§£å’Œå¤šè½®æ£€ç´¢
- ğŸ“Š **ç»“æ„åŒ–ç»“æœ**: éœ€è¦ç»“æ„åŒ–çš„åˆ†æç»“æœ
- ğŸ”— **è·¨æ–‡æ¡£æ•´åˆ**: å¤šæ–‡æ¡£ä¿¡æ¯æ•´åˆå’Œå…³è”åˆ†æ

### é€‰æ‹©Conversationæ¨¡å¼å½“éœ€è¦ï¼š
- âš¡ **å¿«é€Ÿé—®ç­”**: ç®€å•ç›´æ¥çš„é—®ç­”éœ€æ±‚
- ğŸ’¬ **å¯¹è¯è¿ç»­æ€§**: é‡è§†å¯¹è¯å†å²å’Œä¸Šä¸‹æ–‡è¿è´¯æ€§
- ğŸ“š **ä¼šè¯ç®¡ç†**: éœ€è¦å®Œæ•´çš„å¯¹è¯è®°å½•å’Œç®¡ç†
- ğŸ’° **èµ„æºæ§åˆ¶**: å¯¹å“åº”æ—¶é—´å’Œèµ„æºä½¿ç”¨æœ‰ä¸¥æ ¼è¦æ±‚

## ğŸ“ æ€»ç»“

ä¸¤ç§å¯¹è¯æ¨¡å¼éƒ½å……åˆ†åˆ©ç”¨äº†å‘é‡æ£€ç´¢æŠ€æœ¯ï¼Œä½†ä½“ç°äº†ä¸åŒçš„è®¾è®¡å“²å­¦ï¼š

1. **Agentæ¨¡å¼**: "æ·±åº¦ä¼˜å…ˆ" - è¿½æ±‚æ£€ç´¢ç²¾åº¦å’Œç»“æœè´¨é‡ï¼Œé€‚åˆä¸“ä¸šåˆ†æåœºæ™¯
2. **Conversationæ¨¡å¼**: "æ•ˆç‡ä¼˜å…ˆ" - è¿½æ±‚å“åº”é€Ÿåº¦å’Œç®€å•æ˜“ç”¨ï¼Œé€‚åˆæ—¥å¸¸å¯¹è¯åœºæ™¯

è¿™ç§è®¾è®¡ç¡®ä¿äº†ç³»ç»Ÿæ—¢èƒ½æ»¡è¶³ä¸“ä¸šç”¨æˆ·çš„æ·±åº¦åˆ†æéœ€æ±‚ï¼Œåˆèƒ½ä¸ºæ™®é€šç”¨æˆ·æä¾›æµç•…çš„å¯¹è¯ä½“éªŒï¼ŒçœŸæ­£å®ç°äº†æ™ºèƒ½åŒ–ä¸å®ç”¨æ€§çš„å¹³è¡¡ã€‚ 